{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cross_validation as CV\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from datetime import date\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myScore(y, y_pred):\n",
    "    res = np.ndarray([1,2]);\n",
    "    u = (np.power((y-y_pred),2)).sum();\n",
    "    v = (np.power((y-y.mean()),2)).sum();\n",
    "    res[0,0] = 1-(u/v);\n",
    "\n",
    "    \n",
    "    yLog = np.log(y);\n",
    "    ind = np.isinf(yLog);\n",
    "    yLog[ind == True] = 0; \n",
    "    y_predLog = np.log(y_pred);\n",
    "    ind = np.isinf(y_predLog);\n",
    "    y_predLog[ind == True] = 0;   \n",
    "    summ = np.sum(np.power(yLog-y_predLog,2))\n",
    "    res[0,1] = np.sqrt(summ/y.shape[0]);\n",
    "\n",
    "    return res\n",
    "\n",
    "# replace qualitative estimation to number\n",
    "def replaceQualVal(dataSet,fNameList):\n",
    "    # dictionary of values\n",
    "    vocab = {\n",
    "        'Ex': 5, 'EX': 5, # excellent    \n",
    "        'Gd': 4, 'GD': 4, # good\n",
    "        'TA': 3, 'Ta': 3, # normal\n",
    "        'FA': 2, 'Fa': 2, # fair\n",
    "        'PO': 1, 'Po': 1  # \n",
    "        }\n",
    "    \n",
    "    for fName in fNameList:\n",
    "        \n",
    "        # replace stings to numbers\n",
    "        for word in vocab:\n",
    "            searchDict = {fName:[word]};\n",
    "            X = dataSet.isin(searchDict);\n",
    "            dataSet.loc[X[fName],fName] = vocab[word];\n",
    "        \n",
    "        # convert to numeric type\n",
    "        dataSet[[fName]] = dataSet[[fName]].apply(pd.to_numeric);\n",
    "    return dataSet;\n",
    "\n",
    "# replace YN estimation to number\n",
    "def replaceYNVal(dataSet,fNameList):\n",
    "    # dictionary of values\n",
    "    vocab = {\n",
    "        'Yes': 1, 'Y': 5, # yes\n",
    "        'No': 1, 'N': 1  # no\n",
    "        }\n",
    "    \n",
    "    for fName in fNameList:\n",
    "        \n",
    "        # replace stings to numbers\n",
    "        for word in vocab:\n",
    "            searchDict = {fName:[word]};\n",
    "            X = dataSet.isin(searchDict);\n",
    "            dataSet.loc[X[fName],fName] = vocab[word];\n",
    "        \n",
    "        # convert to numeric type\n",
    "        dataSet[[fName]] = dataSet[[fName]].apply(pd.to_numeric);\n",
    "    return dataSet;\n",
    "\n",
    "# main fit function\n",
    "def fitData(folds,regressor,features):\n",
    "    \n",
    "    \n",
    "    num_features = features.select_dtypes(exclude=['object']);\n",
    "    num_features.fillna(0,inplace=True);\n",
    "    \n",
    "    obj_features = features.select_dtypes(include=['object']);\n",
    "    obj_features.fillna('empty',inplace=True)\n",
    "    \n",
    "    encoder = DV(sparse = False);\n",
    "    encoded_data = encoder.fit_transform(obj_features.T.to_dict().values());\n",
    "    \n",
    "    newFeatures = np.hstack([num_features, encoded_data]);\n",
    "\n",
    "    score = np.empty([1,2]);\n",
    "    \n",
    "    for [trainInds, testInds] in folds:\n",
    "        regressor.fit(newFeatures[trainInds,:],price[trainInds]);\n",
    "        y_pr = regressor.predict(newFeatures[testInds,:]);\n",
    "        pr = myScore(price[testInds],y_pr);\n",
    "        print pr\n",
    "        score =  np.append(score,pr,axis = 0);\n",
    "    \n",
    "    score = np.delete(score,0,0);\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv',index_col='Id')\n",
    "features = data.drop('SalePrice',axis = 1)\n",
    "price = data.SalePrice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define regressor\n",
    "trees = GBR(verbose = 0, n_estimators = 1000, max_depth = 3);\n",
    "\n",
    "# define cross-validation folds\n",
    "nFolds = 10;\n",
    "folds = CV.KFold(price.size, n_folds=nFolds, random_state = 43);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageCond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:   50.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89425092  0.12444177]]\n",
      "BsmtCond\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:   48.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89783034  0.12349302]]\n",
      "HeatingQC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3d63a2f47596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mnewFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0my_pr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mmyScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1255\u001b[0m                                                       \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m                                                       fit_params)\n\u001b[1;32m-> 1257\u001b[1;33m                             for train, test in cv)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds_blocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = data.drop('SalePrice',axis = 1)\n",
    "price = data['SalePrice'].get_values()\n",
    "\n",
    "\n",
    "#features[\"OverallQualLog\"]=np.log(features[\"OverallQual\"])\n",
    "#features.drop(['OverallQual'],axis = 1,inplace = True);\n",
    "\n",
    "# drop heating type\n",
    "#features.drop('Heating',axis = 1,inplace = True);\n",
    "#features.drop(['MoSold', 'YrSold'],axis = 1,inplace = True);\n",
    "features = replaceYNVal(features,{'CentralAir'});\n",
    "\n",
    "# process GarageYrBlt\n",
    "empty = pd.isnull(features['GarageYrBlt']);\n",
    "ind = empty[empty == True].index;\n",
    "features.loc[ind.values,'GarageYrBlt'] = features.loc[ind.values,'YearBuilt'];\n",
    "\n",
    "# add new feature\n",
    "features.loc[:,'houseAgeLog'] = np.log(date.today().year - features.loc[:,'YearBuilt']);\n",
    "features.loc[:,'garageAgeLog'] = np.log(date.today().year - features.loc[:,'GarageYrBlt']);\n",
    "features.loc[:,'remodeAge'] = features.loc[:,'YearRemodAdd'] - features.loc[:,'YearBuilt'];\n",
    "\n",
    "\n",
    "featureList = {'ExterQual','ExterCond','BsmtQual','BsmtCond','PoolQC','HeatingQC','KitchenQual','GarageQual',\n",
    "               'GarageCond','FireplaceQu','PoolQC'};\n",
    "\n",
    "for fName in featureList:\n",
    "    print fName\n",
    "    newFeatures = replaceQualVal(features,{fName});\n",
    "    \n",
    "    num_features = newFeatures.select_dtypes(exclude=['object']);\n",
    "    num_features.fillna(0,inplace=True);\n",
    "    \n",
    "    obj_features = newFeatures.select_dtypes(include=['object']);\n",
    "    obj_features.fillna('empty',inplace=True)\n",
    "    encoder = DV(sparse = False);\n",
    "    encoded_data = encoder.fit_transform(obj_features.T.to_dict().values());\n",
    "    newFeatures = np.hstack([num_features, encoded_data]);\n",
    "       \n",
    "    y_pr = CV.cross_val_predict(trees, newFeatures, y=price, cv=folds, n_jobs=8, verbose=1)\n",
    "    print myScore(price, y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
